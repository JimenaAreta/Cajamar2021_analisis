{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuente datos : https://www.mapa.gob.es/app/consumo-en-hogares/consulta11.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se han obtenido a través del scrapping de la página web del MAPA seleccionando:\n",
    "- Grupo de productos : \"Frutas Frescas\" y \"Patatas y Hortalizas\"\n",
    "- Tipo de establecimiento: \"Internet\", \"Hipermercado\" y \"Supermercado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es_ES.UTF-8'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importan las librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de hortalizas a través de hipermercados\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_hh (hortalizas-hipermercado)\n",
    "files = os.listdir(\"canalesVenta_Hortalizas_2013_2020/Hipermercados\")\n",
    "frames = []\n",
    "df_hh = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"canalesVenta_Hortalizas_2013_2020/Hipermercados/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_hh = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de hortalizas a través de internet\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_hi (hortalizas-internet)\n",
    "files = os.listdir(\"canalesVenta_Hortalizas_2013_2020/Internet\")\n",
    "frames = []\n",
    "df_hi = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"canalesVenta_Hortalizas_2013_2020/Internet/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_hi = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de frutas a través de hipermercado\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_fh (frutas-hipermercado)\n",
    "files = os.listdir(\"canalesVenta_Frutas_2013_2020/Hipermercados\")\n",
    "frames = []\n",
    "df_fh = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"canalesVenta_Frutas_2013_2020/Hipermercados/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_fh = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de frutas a través de internet\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_fi (frutas-internet)\n",
    "files = os.listdir(\"canalesVenta_Frutas_2013_2020/Internet\")\n",
    "frames = []\n",
    "df_fi = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"canalesVenta_Frutas_2013_2020/Internet/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_fi = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de frutas a través de supermercados\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_fs (frutas-supermercado)\n",
    "files = os.listdir(\"Supermercado_Frutas\")\n",
    "frames = []\n",
    "df_fs = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"Supermercado_Frutas/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_fs = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con todos los archivos csv de consumo de hortalizas a través de supermercados\n",
    "# Se limpian los datos eliminando las columnas vacías\n",
    "# Correción de los valores de las columnas que salen multiplicados por 100 porque al descargarlos del MAPA con el scrapping se elimina la coma\n",
    "# Se crea el dataset df_hs (hortalizas-supermercado)\n",
    "files = os.listdir(\"Supermercado_Hortalizas\")\n",
    "frames = []\n",
    "df_hs = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"Supermercado_Hortalizas/\" + file, encoding = 'utf-8-sig',thousands='.')\n",
    "    df.drop(columns = ['Unnamed: 5','Unnamed: 6'],inplace = True)\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(float)/100\n",
    "    frames.append(df)\n",
    "df_hs = pd.concat(frames,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza una máscara con los meses para pasarlos a número\n",
    "lista_mes= ['Enero','Febrero','Marzo','Abril','Mayo','Junio','Julio','Agosto','Septiembre','Octubre','Noviembre','Diciembre']\n",
    "mask1 = df_fi['Mes'].isin(lista_mes)\n",
    "df_fi = df_fi[mask1]\n",
    "mask2 = df_fh['Mes'].isin(lista_mes)\n",
    "df_fh = df_fh[mask2]\n",
    "mask3 = df_hh['Mes'].isin(lista_mes)\n",
    "df_hh = df_hh[mask3]\n",
    "mask4 = df_hi['Mes'].isin(lista_mes)\n",
    "df_hi = df_hi[mask4]\n",
    "mask5 = df_hs['Mes'].isin(lista_mes)\n",
    "df_hs = df_hs[mask5]\n",
    "mask6 = df_fs['Mes'].isin(lista_mes)\n",
    "df_fs = df_fs[mask6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos todos los meses de dataset a número y se crea la columna fecha con el mes y el año\n",
    "# Se convierte la columna fecha a índice\n",
    "# Se ordena la columna fecha por año y mes\n",
    "# Se realiza este proceso con todos los datasets\n",
    "df_fi['Mes'] = pd.to_datetime(df_fi['Mes'], format='%B').dt.month\n",
    "df_fi['Fecha'] =  pd.to_datetime(df_fi['Año'].map(str) + '-' + df_fi['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_fi.set_index('Fecha',inplace=True)\n",
    "df_fi.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh['Mes'] = pd.to_datetime(df_fh['Mes'], format='%B').dt.month\n",
    "df_fh['Fecha'] =  pd.to_datetime(df_fh['Año'].map(str) + '-' + df_fh['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_fh.set_index('Fecha',inplace=True)\n",
    "df_fh.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi['Mes'] = pd.to_datetime(df_hi['Mes'], format='%B').dt.month\n",
    "df_hi['Fecha'] =  pd.to_datetime(df_hi['Año'].map(str) + '-' + df_hi['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_hi.set_index('Fecha',inplace=True)\n",
    "df_hi.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh['Mes'] = pd.to_datetime(df_hh['Mes'], format='%B').dt.month\n",
    "df_hh['Fecha'] =  pd.to_datetime(df_hh['Año'].map(str) + '-' + df_hh['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_hh.set_index('Fecha',inplace=True)\n",
    "df_hh.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs['Mes'] = pd.to_datetime(df_hs['Mes'], format='%B').dt.month\n",
    "df_hs['Fecha'] =  pd.to_datetime(df_hs['Año'].map(str) + '-' + df_hs['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_hs.set_index('Fecha',inplace=True)\n",
    "df_hs.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fs['Mes'] = pd.to_datetime(df_fs['Mes'], format='%B').dt.month\n",
    "df_fs['Fecha'] =  pd.to_datetime(df_fs['Año'].map(str) + '-' + df_fs['Mes'].map(str)).dt.strftime('%m-%Y')\n",
    "df_fs.set_index('Fecha',inplace=True)\n",
    "df_fs.sort_values(by = ['Año','Mes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Se guardan todos los datasets para el análisis posterior en PowerBI\n",
    "# df_fi.to_csv(\"Consumo_2013_2020_frutas_internet.csv\", encoding = 'utf-8-sig')\n",
    "# df_hi.to_csv(\"Consumo_2013_2020_hortalizas_internet.csv\", encoding = 'utf-8-sig')\n",
    "# df_hh.to_csv(\"Consumo_2013_2020_hortalizas_hipermercado.csv\", encoding = 'utf-8-sig')\n",
    "# df_fh.to_csv(\"Consumo_2013_2020_frutas_hipermercado.csv\", encoding = 'utf-8-sig')\n",
    "# df_fs.to_csv(\"Consumo_2013_2020_frutas_supermercado.csv\", encoding = 'utf-8-sig')\n",
    "# df_hs.to_csv(\"Consumo_2013_2020_hortalizas_supermercado.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los datasets por lugar de compra concatenando los datasets de frutas y hortalizas por cada lugar de compra\n",
    "df_internet = pd.concat([df_hi,df_fi], axis = 0)\n",
    "df_hipermercado = pd.concat([df_hh,df_fh], axis = 0)\n",
    "df_supermercado = pd.concat([df_hs,df_fs], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Se guardan los datasets para el análisis posterior\n",
    "# df_internet.to_csv(\"Consumo_2013_2020_internet.csv\", encoding = 'utf-8-sig')\n",
    "# df_hipermercado.to_csv(\"Consumo_2013_2020_hipermercado.csv\", encoding = 'utf-8-sig')\n",
    "# df_supermercado.to_csv(\"Consumo_2013_2020_supermercado.csv\", encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
